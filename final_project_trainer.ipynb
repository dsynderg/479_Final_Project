{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMFJLgFC37q5gN05lEknQBq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsynderg/479_Final_Project/blob/main/final_project_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenNMT-py\n",
        "!pip install \"numpy<2.0\" # This fixes an error caused by OpenNMT not being maintained"
      ],
      "metadata": {
        "id": "zrZNv7GUYYyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "!wget https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz\n",
        "!tar xf toy-ende.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrIXuT1YPlDQ",
        "outputId": "f90a0c4e-846c-4840-9f01-990ac213250e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py\n",
            "  Using cached OpenNMT_py-3.5.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting torch<2.3,>=2.1 (from OpenNMT-py)\n",
            "  Using cached torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting configargparse (from OpenNMT-py)\n",
            "  Using cached configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ctranslate2<5,>=4 (from OpenNMT-py)\n",
            "  Using cached ctranslate2-4.6.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.12/dist-packages (from OpenNMT-py) (2.19.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (from OpenNMT-py) (3.1.2)\n",
            "Collecting waitress (from OpenNMT-py)\n",
            "  Using cached waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "INFO: pip is looking at multiple versions of opennmt-py to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting OpenNMT-py\n",
            "  Using cached OpenNMT_py-3.5.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "  Using cached OpenNMT_py-3.4.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "  Using cached OpenNMT_py-3.4.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "  Using cached OpenNMT_py-3.4.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Using cached OpenNMT_py-3.4-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Using cached OpenNMT_py-3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Using cached OpenNMT_py-3.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is still looking at multiple versions of opennmt-py to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached OpenNMT_py-3.1.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Using cached OpenNMT_py-3.1.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "  Using cached OpenNMT_py-3.1.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Using cached OpenNMT_py-3.0.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: torch>=1.12.1 in /usr/local/lib/python3.12/dist-packages (from OpenNMT-py) (2.9.0+cu126)\n",
            "Collecting ctranslate2<4,>=3.2 (from OpenNMT-py)\n",
            "  Using cached ctranslate2-3.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting OpenNMT-py\n",
            "  Using cached OpenNMT_py-3.0.3-py3-none-any.whl.metadata (14 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached OpenNMT_py-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "  Using cached OpenNMT_py-3.0.1-py3-none-any.whl.metadata (14 kB)\n",
            "  Using cached OpenNMT_py-3.0.0-py3-none-any.whl.metadata (14 kB)\n",
            "  Using cached OpenNMT_py-2.3.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torchtext==0.5.0 (from OpenNMT-py)\n",
            "  Using cached torchtext-0.5.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting OpenNMT-py\n",
            "  Using cached OpenNMT_py-2.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from OpenNMT-py) (6.0.3)\n",
            "  Using cached OpenNMT_py-2.1.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.51 in /usr/local/lib/python3.12/dist-packages (from OpenNMT-py) (4.67.1)\n",
            "  Using cached OpenNMT_py-2.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "  Using cached OpenNMT_py-2.1.0-py3-none-any.whl.metadata (14 kB)\n",
            "  Using cached OpenNMT_py-2.0.1-py3-none-any.whl.metadata (14 kB)\n",
            "  Using cached OpenNMT_py-2.0.0-py3-none-any.whl.metadata (14 kB)\n",
            "  Using cached OpenNMT_py-1.2.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from OpenNMT-py) (1.17.0)\n",
            "Collecting torchtext==0.4.0 (from OpenNMT-py)\n",
            "  Using cached torchtext-0.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from OpenNMT-py) (1.0.0)\n",
            "Collecting OpenNMT-py\n",
            "  Using cached OpenNMT_py-1.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting tqdm~=4.30.0 (from OpenNMT-py)\n",
            "  Using cached tqdm-4.30.0-py2.py3-none-any.whl.metadata (37 kB)\n",
            "Collecting OpenNMT-py\n",
            "  Using cached OpenNMT_py-1.1.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Using cached OpenNMT_py-1.0.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Using cached OpenNMT_py-1.0.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Using cached OpenNMT_py-1.0.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "\u001b[31mERROR: Cannot install opennmt-py==1.0.0, opennmt-py==1.0.1, opennmt-py==1.0.2, opennmt-py==1.1.0, opennmt-py==1.1.1, opennmt-py==1.2.0, opennmt-py==2.0.0, opennmt-py==2.0.1, opennmt-py==2.1.0, opennmt-py==2.1.1, opennmt-py==2.1.2, opennmt-py==2.2.0, opennmt-py==2.3.0, opennmt-py==3.0.0, opennmt-py==3.0.1, opennmt-py==3.0.2, opennmt-py==3.0.3, opennmt-py==3.0.4, opennmt-py==3.1.1, opennmt-py==3.1.2, opennmt-py==3.1.3, opennmt-py==3.2.0, opennmt-py==3.3, opennmt-py==3.4, opennmt-py==3.4.1, opennmt-py==3.4.2, opennmt-py==3.4.3, opennmt-py==3.5.0 and opennmt-py==3.5.1 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    opennmt-py 3.5.1 depends on pyonmttok<2 and >=1.37\n",
            "    opennmt-py 3.5.0 depends on pyonmttok<2 and >=1.35\n",
            "    opennmt-py 3.4.3 depends on torch<2.2 and >=2.0.1\n",
            "    opennmt-py 3.4.2 depends on torch<2.2 and >=2.0.1\n",
            "    opennmt-py 3.4.1 depends on torch<2.1 and >=2.0\n",
            "    opennmt-py 3.4 depends on torch<2.1 and >=1.13\n",
            "    opennmt-py 3.3 depends on torch<2.1 and >=1.13\n",
            "    opennmt-py 3.2.0 depends on torch<2 and >=1.13\n",
            "    opennmt-py 3.1.3 depends on torch<2 and >=1.13\n",
            "    opennmt-py 3.1.2 depends on torch<2 and >=1.13\n",
            "    opennmt-py 3.1.1 depends on torch<2 and >=1.13\n",
            "    opennmt-py 3.0.4 depends on pyonmttok<2 and >=1.35\n",
            "    opennmt-py 3.0.3 depends on pyonmttok<2 and >=1.35\n",
            "    opennmt-py 3.0.2 depends on pyonmttok<2 and >=1.35\n",
            "    opennmt-py 3.0.1 depends on pyonmttok<2 and >=1.34\n",
            "    opennmt-py 3.0.0 depends on pyonmttok<2 and >=1.23\n",
            "    opennmt-py 2.3.0 depends on pyonmttok<2 and >=1.23\n",
            "    opennmt-py 2.2.0 depends on pyonmttok<2 and >=1.23; platform_system == \"Linux\" or platform_system == \"Darwin\"\n",
            "    opennmt-py 2.1.2 depends on torch==1.6.0\n",
            "    opennmt-py 2.1.1 depends on torch==1.6.0\n",
            "    opennmt-py 2.1.0 depends on torch==1.6.0\n",
            "    opennmt-py 2.0.1 depends on torch==1.6.0\n",
            "    opennmt-py 2.0.0 depends on torch==1.6.0\n",
            "    opennmt-py 1.2.0 depends on pyonmttok==1.*; platform_system == \"Linux\"\n",
            "    opennmt-py 1.1.1 depends on pyonmttok==1.*; platform_system == \"Linux\"\n",
            "    opennmt-py 1.1.0 depends on pyonmttok==1.*; platform_system == \"Linux\"\n",
            "    opennmt-py 1.0.2 depends on pyonmttok==1.*; platform_system == \"Linux\"\n",
            "    opennmt-py 1.0.1 depends on pyonmttok==1.*; platform_system == \"Linux\"\n",
            "    opennmt-py 1.0.0 depends on pyonmttok==1.*; platform_system == \"Linux\"\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "--2025-11-25 18:58:03--  https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.15.181.220, 16.15.189.155, 52.217.226.24, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.15.181.220|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1662081 (1.6M) [application/x-gzip]\n",
            "Saving to: ‘toy-ende.tar.gz.2’\n",
            "\n",
            "toy-ende.tar.gz.2   100%[===================>]   1.58M  4.32MB/s    in 0.4s    \n",
            "\n",
            "2025-11-25 18:58:04 (4.32 MB/s) - ‘toy-ende.tar.gz.2’ saved [1662081/1662081]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja_Tu-M5Nzb0"
      },
      "outputs": [],
      "source": [
        "def fileSplitter(file):\n",
        "  returnlist = []\n",
        "  with open(file,'r') as f:\n",
        "    for line in f:\n",
        "      returnlist.append(line.split('\\t'))\n",
        "  return returnlist\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taggeddata = fileSplitter('/content/tagged_omni_64_thousand_PopandEnglish.txt')"
      ],
      "metadata": {
        "id": "pgXuXcNMPC7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taggeddata[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5UK5w1JPQDf",
        "outputId": "f565ba24-fad6-4bde-da16-0c2a312e0cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<Papiamento> Selections From The Book of Mormon',\n",
              "  'Selekshonnan For Di E Buki Di Mormon\\n'],\n",
              " ['<Papiamento> This volume contains selections from the Book of Mormon.',\n",
              "  'E volumen aki ta kontené selekshonnan for di e Buki di Mormon.\\n'],\n",
              " ['<Papiamento> At that time, this volume will be discontinued.',\n",
              "  'Na e momento ei, e volumen aki lo wòrdu deskontinuá.\\n'],\n",
              " ['<Papiamento> The Book of Mormon contains the fullness of the gospel of Jesus Christ.',\n",
              "  'E Buki di Mormon ta poseé e plenitut di e evangelio di Jesucristo.\\n'],\n",
              " ['<Papiamento> Published by The Church of Jesus Christ of Latter-day Saints',\n",
              "  'Publiká dor di e Iglesia di Jesucristo di e Santunan di e Delaster Dianan.\\n'],\n",
              " ['<Papiamento> Salt Lake City, Utah, USA', 'Salt Lake City, Utah 1990\\n'],\n",
              " ['<Papiamento> title page of the Book of Mormon',\n",
              "  'pagina di titulo di e Buki di Mormon\\n'],\n",
              " ['<Papiamento> Title Page of the Book of Mormon',\n",
              "  'pagina di titulo di e Buki di Mormon\\n'],\n",
              " ['<Papiamento> An Account Written by the Hand of Mormon upon Plates Taken from the Plates of Nephi',\n",
              "  'Un Historia Skirbí Pa E Man Di Mormon Riba Plachinan Tuma For Di E Plachinan Di Nefi\\n'],\n",
              " ['<Papiamento> Translated into English by Joseph Smith, Jun.',\n",
              "  'Tradusí na ingles pa José Smith, Jun.\\n']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RSpDn_naP7q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "random.shuffle(taggeddata)\n",
        "taggeddata[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "R45lczMePdq3",
        "outputId": "7243cfc7-ec96-4e89-a524-c8764cc2d3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"<Papiamento> Several years ago, Sister Pearson and I were called to preside over the Washington Tacoma Mission. The call was a complete surprise. With some trepidation I met with the chairman and the CEO of the company where I was employed and informed them of my mission call. They were visibly upset with my decision to leave the firm. 'When did you make this decision, and why didn't you discuss it with us earlier?' they demanded.\",\n",
              "  'Vários aña pasa, Hermana Pearson i ami a wòrdu yama pa presidí riba e Mishon Washington Tacoma. E yamamentu tabata un sorpresa grandi. Ku algu di miedu mi a reuní ku e presidente i direktor di e kompania kaminda mi tabata traha i informe di mi yamamentu misional. E tabata visiblemente rabia ku mi desishon di bandoná e empresa. Ki dia bo a tuma e desishon aki, i dikon bo no a diskutié ku nos promé? nan a eksigí pa sa.\\n'],\n",
              " [\"<Papiamento> Reflecting on this and other examples of once flourishing societies that later foundered, I think it safe to say that when people turn from a sense of accountability to God and begin to trust instead in the 'arm of flesh,' disaster lurks.\",\n",
              "  \"Refleksionando riba esaki i otro ehèmpelnan di sosiedatnan ku un tempu tabata floresiente i ku despues a hundi, mi ta pensa ta seif pa bisa ku ora hende kita for di un sentido di responsabilidat na Dios i kuminsá konfia den e 'brasa di karni,' desaster ta lur.\\n\"],\n",
              " ['<Papiamento> This covenant path is the way we come unto Christ and is based on absolute truth and eternal, unchanging law.',\n",
              "  'E kaminda di konvenio aki ta e kaminda ku nos ta bini na Cristo i ta basá riba bèrdat apsoluto i eterno, lei ku no ta kambia.\\n'],\n",
              " [\"<Papiamento> Alma's call for us to desire to believe and to 'give place' in our hearts for the Savior's words reminds us that belief and faith require our personal choice and action.\",\n",
              "  \"Alma su yamada na nos pa deseá di kere i pa 'duna lugá' den nos kurason na e Salbador su palabranan ta rekordá nos ku kere i fe ta rekerí nos eskoho i akshon personal.\\n\"],\n",
              " ['<Papiamento> If we stop doing those things that bring about deepening conversion, we regress spiritually.',\n",
              "  'Si nos stòp di hasi e kosnan ku ta trese kombershon profundo, nos lo bai atras spiritualmente.\\n'],\n",
              " ['<Papiamento> See Joseph Fielding Smith, Answers to Gospel Questions, comp. Joseph Fielding Smith Jr., 5 vols. (1957–66), 4:166.',\n",
              "  'Wak Joseph Fielding Smith, Answers to Gospel Questions, comp. Joseph Fielding Smith Jr., 5 vols. (1957–66), 4:166.\\n'],\n",
              " ['<English> Un miembro a relatá, Nos a bishitá e tèmpel hopi, hopi biaha.',\n",
              "  \"One member recorded: We've been to the temple many, many times.\\n\"],\n",
              " ['<English> Mi ta bai pa tuma di e santa cena.',\n",
              "  'I go to partake of the sacrament.\\n'],\n",
              " ['<English> Dor di e abundansha di informashon, algun inkonsientemente, ta duna mas kredibilidat na fuentenan aksesibel ku un orígen deskonosí mas ku konfia Señora su patronchi establesé pa risibí revelashon personal.',\n",
              "  \"Because of the abundance of information, some unwittingly give more credibility to available sources with an unknown origin rather than relying on the Lord's established pattern for receiving personal revelation.\\n\"],\n",
              " [\"<Papiamento> 'Therefore ye must always pray unto the Father in my name.'\",\n",
              "  \"'Di manera ku boso mester hasi orashon semper na e Tata den mi nòmber.' 33\\n\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"src_val.txt\",'w') as srcVal:\n",
        "  with open('tgt_val.txt','w') as tgtVal:\n",
        "    validationList = taggeddata[:2000]\n",
        "    del taggeddata[:2000]\n",
        "    print(validationList[0])\n",
        "    for i in validationList:\n",
        "      srcVal.write(f'{i[0].strip()}\\n')\n",
        "      tgtVal.write(f'{i[1].strip()}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol0wgGYeQBES",
        "outputId": "7f69b2fc-bdbc-4704-f49a-347a5a48064d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"<Papiamento> Several years ago, Sister Pearson and I were called to preside over the Washington Tacoma Mission. The call was a complete surprise. With some trepidation I met with the chairman and the CEO of the company where I was employed and informed them of my mission call. They were visibly upset with my decision to leave the firm. 'When did you make this decision, and why didn't you discuss it with us earlier?' they demanded.\", 'Vários aña pasa, Hermana Pearson i ami a wòrdu yama pa presidí riba e Mishon Washington Tacoma. E yamamentu tabata un sorpresa grandi. Ku algu di miedu mi a reuní ku e presidente i direktor di e kompania kaminda mi tabata traha i informe di mi yamamentu misional. E tabata visiblemente rabia ku mi desishon di bandoná e empresa. Ki dia bo a tuma e desishon aki, i dikon bo no a diskutié ku nos promé? nan a eksigí pa sa.\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"src_test.txt\",'w') as srcVal:\n",
        "  with open('tgt_test.txt','w') as tgtVal:\n",
        "    validationList = taggeddata[-2000:]\n",
        "    del taggeddata[-2000:]\n",
        "    print(validationList[0])\n",
        "    for i in validationList:\n",
        "      srcVal.write(f'{i[0].strip()}\\n')\n",
        "      tgtVal.write(f'{i[1].strip()}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc6pZdDKRF7g",
        "outputId": "a88431a9-b50a-49d1-daea-073ca75b5112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<Papiamento> This type of relief, besides being temporary, will ultimately bring more pain and grief into our lives and will diminish our possibility of receiving a remission of our sins.', 'E tipo di alivio aki, ademas di ta temporal, últimamente lo trese mas dolor i angustia den nos bida i lo redusí nos posibilidat pa risibí remishon di nos pikanan.\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"src_train.txt\",'w') as srcVal:\n",
        "  with open('tgt_train.txt','w') as tgtVal:\n",
        "    validationList = taggeddata\n",
        "    print(validationList[0])\n",
        "    for i in validationList:\n",
        "      srcVal.write(f'{i[0].strip()}\\n')\n",
        "      tgtVal.write(f'{i[1].strip()}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6xvu9M-S-Ir",
        "outputId": "d8dd5289-443b-422c-fe19-de16774a5ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<Papiamento> With the passage of time, moral agency and mortal experiences help us become more like our Savior as we labor with Him in His vineyard and follow His covenant path.', \"Ku e paso di tempu, agensia moral i eksperiensia mortal ta yuda nos bira mas manera nos Salbador i ora nos ta laborá ku n'E den Su kunuku di biña.2 i sigui su kaminda di konvenio.\\n\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no2c0O0vTc6N",
        "outputId": "58eddc22-8ecd-4b81-c738-ac10daae1f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "spm.SentencePieceTrainer.train(\n",
        "  input='src_train.txt',\n",
        "  model_prefix='english_sp_model',\n",
        "  vocab_size=16000,\n",
        ")\n",
        "\n",
        "spm.SentencePieceTrainer.train(\n",
        "  input='tgt_train.txt',\n",
        "  model_prefix='spanish_sp_model',\n",
        "  vocab_size=16000,\n",
        ")"
      ],
      "metadata": {
        "id": "AP1NPT6STho6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install OpenNMT-py\n",
        "# !pip install torch==2.0.1\n",
        "# !pip install pyonmttok==1.37\n",
        "# !pip install opennmt-py==3.5.1\n",
        "\n"
      ],
      "metadata": {
        "id": "KtQAgB__TizN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build YAML Config file\n",
        "yaml_text = \"\"\"\n",
        "# sentance_peice_yaml.yaml\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: /content/example\n",
        "\n",
        "src_vocab: /content/example.vocab.src\n",
        "tgt_vocab: /content/example.vocab.tgt\n",
        "\n",
        "# Prevent overwriting existing files in the folder\n",
        "overwrite: True\n",
        "\n",
        "# -- Sentencepiece Params --\n",
        "# Tokenization options\n",
        "src_subword_type: sentencepiece\n",
        "src_subword_model: english_sp_model.model\n",
        "tgt_subword_type: sentencepiece\n",
        "tgt_subword_model: spanish_sp_model.model\n",
        "\n",
        "# Number of candidates for SentencePiece sampling\n",
        "subword_nbest: 20\n",
        "# Smoothing parameter for SentencePiece sampling\n",
        "subword_alpha: 0.1\n",
        "# Specific arguments for pyonmttok\n",
        "src_onmttok_kwargs: \"{'mode': 'none', 'spacer_annotate': True}\"\n",
        "tgt_onmttok_kwargs: \"{'mode': 'none', 'spacer_annotate': True}\"\n",
        "\n",
        "\n",
        "# Corpus opts:\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: /content/src_train.txt\n",
        "        path_tgt: /content/tgt_train.txt\n",
        "        transforms: [onmt_tokenize]\n",
        "    valid:\n",
        "        path_src: /content/src_val.txt\n",
        "        path_tgt: /content/tgt_val.txt\n",
        "        transforms: [onmt_tokenize]\n",
        "\n",
        "# Train on a single GPU\n",
        "bucket_size: 10000\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Where to save the checkpoints\n",
        "save_model: /content/modle\n",
        "save_checkpoint_steps: 2000\n",
        "train_steps: 20000\n",
        "valid_steps: 500\n",
        "\"\"\"\n",
        "\n",
        "with open(\"sentance_peice_yaml.yaml\", \"w\") as f:\n",
        "    f.write(yaml_text)"
      ],
      "metadata": {
        "id": "WfbihqdnTk_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_build_vocab -config sentance_peice_yaml.yaml"
      ],
      "metadata": {
        "id": "UG0h23SCTuXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_train -config sentance_peice_yaml.yaml"
      ],
      "metadata": {
        "id": "_0F6lHBDTxR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate_yaml_text = \"\"\"\n",
        "model: /content/modle_step_20000_sentance_peice.pt\n",
        "src: /content/src_test.txt\n",
        "output: /content/sentancepeice_2000.txt\n",
        "gpu: 0\n",
        "verbose: True\n",
        "\n",
        "# Sentencepiece Params\n",
        "\n",
        "# Tokenization options\n",
        "transforms: onmt_tokenize\n",
        "src_subword_type: sentencepiece\n",
        "src_subword_model: english_sp_model.model\n",
        "tgt_subword_type: sentencepiece\n",
        "tgt_subword_model: spanish_sp_model.model\n",
        "\n",
        "src_subword_nbest: 20\n",
        "src_subword_alpha: 0.1\n",
        "\"\"\"\n",
        "\n",
        "with open(\"translate_yaml.yaml\", \"w\") as f:\n",
        "    f.write(translate_yaml_text)"
      ],
      "metadata": {
        "id": "Hm83kongT4sd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}